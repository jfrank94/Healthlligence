{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dWkTTaAe10KQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWkTTaAe10KQ",
    "outputId": "9cd56a18-1700-4dcb-8d2b-3c547e58bf1f"
   },
   "outputs": [],
   "source": [
    "# !pip install image-quality\n",
    "# !pip install opencv-python==4.6.0.66\n",
    "# !pip install scikit-learn\n",
    "#!python image-quality/setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75f56bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brisque in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (0.0.12)\n",
      "Requirement already satisfied: libsvm in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from brisque) (3.23.0.4)\n",
      "Requirement already satisfied: opencv-python in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from brisque) (4.6.0.66)\n",
      "Requirement already satisfied: scipy in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from brisque) (1.7.1)\n",
      "Requirement already satisfied: numpy in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from brisque) (1.21.2)\n",
      "Requirement already satisfied: scikit-image in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from brisque) (0.19.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (2.8.4)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (1.3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (2.19.3)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from scikit-image->brisque) (2022.5.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/jfhealthlligence/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->scikit-image->brisque) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/Users/jfhealthlligence/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install brisque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f17c8d3-ae09-4974-b871-5f1a29150a9e",
   "metadata": {
    "id": "9f17c8d3-ae09-4974-b871-5f1a29150a9e"
   },
   "outputs": [],
   "source": [
    "#import imquality.brisque as brisque\n",
    "from brisque import BRISQUE\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import skimage\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "611f92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r sample_images/blur_images\n",
    "# !rm -r sample_images/sharpen_images\n",
    "# !rm -r sample_images/cb_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e38945ef-2f8c-43ac-84d4-e54eb45c2b8a",
   "metadata": {
    "id": "e38945ef-2f8c-43ac-84d4-e54eb45c2b8a"
   },
   "outputs": [],
   "source": [
    "path = \"sample_images\"\n",
    "closed_fn = \"{}/closed_mouth.png\".format(path)\n",
    "open_fn = \"{}/open_mouth.png\".format(path)\n",
    "open_fn_2 = \"{}/img_2.png\".format(path)\n",
    "\n",
    "closed_orig = cv2.imread(closed_fn)\n",
    "open_orig = cv2.imread(open_fn)\n",
    "open_orig_2 = cv2.imread(open_fn_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "DJ5Rqr02sLFX",
   "metadata": {
    "id": "DJ5Rqr02sLFX"
   },
   "outputs": [],
   "source": [
    "def mkdir_(path):\n",
    "  try: \n",
    "    os.mkdir(path) \n",
    "  except OSError as error: \n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "vD9hZPqmrq2G",
   "metadata": {
    "id": "vD9hZPqmrq2G"
   },
   "outputs": [],
   "source": [
    "global blur_path, sharp_path, cb_path\n",
    "blur_path = \"{}/blur_images\".format(path)\n",
    "sharp_path = \"{}/sharpen_images\".format(path)\n",
    "cb_path = \"{}/cb_images\".format(path)\n",
    "\n",
    "# mkdir_(blur_path)\n",
    "# mkdir_(sharp_path)\n",
    "# mkdir_(cb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b771d82-d3fc-4378-911e-c68dcd1ddf71",
   "metadata": {
    "id": "5b771d82-d3fc-4378-911e-c68dcd1ddf71"
   },
   "outputs": [],
   "source": [
    "from numpy import array, linspace\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from matplotlib import pyplot as plt \n",
    "import math\n",
    "\n",
    "class ImageAugLabeling:\n",
    "    \n",
    "    def __init__(self, img, iters, filename):\n",
    "        self.img = img\n",
    "        self.iters = iters\n",
    "        self.filename = filename\n",
    "        self.path = \"sample_images\"\n",
    "        self.blur_path = blur_path\n",
    "        self.sharp_path = sharp_path\n",
    "        self.cb_path = cb_path\n",
    "        self.alpha = 1.0\n",
    "        self.beta = 0\n",
    "        self.brisque_scores = {}\n",
    "    \n",
    "    def brisque_calc(self, file_type, path):\n",
    "        self.brisque_scores = {}\n",
    "        for fn in os.listdir(path):\n",
    "            file = os.path.join(path, fn)\n",
    "            if file_type in file:\n",
    "                # self.img = cv2.imread(file)\n",
    "                file_num = int(re.findall('\\d+', file)[0])\n",
    "                obj = BRISQUE(file, url=False)\n",
    "                brisque_score = obj.score()\n",
    "                if math.isnan(brisque_score):\n",
    "                    brisque_score = 0.0\n",
    "                self.brisque_scores[file_num] = brisque_score\n",
    "        return self.brisque_scores\n",
    "    \n",
    "    def blur_effect(self):\n",
    "        kernel_sizes = [(3, 3)] + [(x+6, x+6) for x in range(0, self.iters*3-3, 3)]\n",
    "        i = 1\n",
    "        for (x, y) in kernel_sizes:\n",
    "            blur = cv2.blur(self.img, (x, y))\n",
    "            blur_filename = \"{}/Blur_{}_{}.jpg\".format(self.blur_path, self.filename, i)\n",
    "            cv2.imwrite(blur_filename, blur)\n",
    "            i += 1 \n",
    "        return self.brisque_calc(\"Blur\", self.blur_path)\n",
    "            \n",
    "    def sharpen(self):\n",
    "       \n",
    "        i = 1\n",
    "        for multiplier in range(5, self.iters*5+1, 5):\n",
    "            blur = cv2.GaussianBlur(self.img, (0, 0), multiplier)\n",
    "            weights = cv2.addWeighted(self.img, 1.5, blur, -0.9, 0)\n",
    "        \n",
    "            h, w = self.img.shape[:2]\n",
    "            sharpened_img = np.zeros([h, w, 3], dtype=self.img.dtype)\n",
    "            sharpened_img[0:h, 0:w, :] = weights\n",
    "            sharpened_filename = \"{}/Sharp_{}_{}.jpg\".format(self.sharp_path, self.filename, i)\n",
    "            cv2.imwrite(sharpened_filename, sharpened_img)\n",
    "            i += 1\n",
    "        return self.brisque_calc(\"Sharp\", self.sharp_path)  \n",
    "        \n",
    "    def contrast_brightness_effect(self):\n",
    "        for i in range(1, self.iters+1//2):\n",
    "            cb_img = cv2.convertScaleAbs(self.img, alpha=self.alpha, beta=self.beta)\n",
    "            self.alpha -= 0.1\n",
    "            cb_filename = \"{}/CB_{}_{}.jpg\".format(self.cb_path, self.filename, i)\n",
    "            cv2.imwrite(cb_filename, cb_img)\n",
    "        for i in range(self.iters+1//2, self.iters+1):\n",
    "            cb_img = cv2.convertScaleAbs(self.img, alpha=self.alpha, beta=self.beta)\n",
    "            self.alpha += 0.1\n",
    "            cb_filename = \"{}/CB_{}_{}.jpg\".format(self.cb_path, self.filename, i)\n",
    "            cv2.imwrite(cb_filename, cb_img)\n",
    "        return self.brisque_calc(\"CB\", self.cb_path)\n",
    "    \n",
    "    def labeling(self, array, model_filename, bandwidth=5, see_plot=False):\n",
    "        scores_labels = {}\n",
    "        ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "        ms.fit(array)\n",
    "        labels = ms.labels_\n",
    "        cluster_centers = ms.cluster_centers_\n",
    "        \n",
    "        \n",
    "        labels_unique = np.unique(labels)\n",
    "        n_clusters_ = len(labels_unique)\n",
    "        if n_clusters_ != 2: \n",
    "            print(\"{}: No. of clusters: {}. Automatic adjusting...\".format(model_filename, n_clusters_))\n",
    "            if n_clusters_ > 2:\n",
    "                bandwidth += 1 \n",
    "            elif n_clusters_ < 2:\n",
    "                bandwidth -= 1\n",
    "            return self.labeling(array, model_filename, bandwidth) #automatic adjustment\n",
    "        else:        \n",
    "            model_filename += \".pkl\"\n",
    "            joblib.dump(ms, model_filename)\n",
    "            ms_loaded = joblib.load(model_filename)\n",
    "            if see_plot:\n",
    "                brisque_scores_test = [[x] for x in np.random.uniform(0.0, 100.0, 50)]\n",
    "                y_pred = ms_loaded.predict(brisque_scores_test)\n",
    "\n",
    "                brisque_scores_1d = [num for arr in brisque_scores_test for num in arr]\n",
    "\n",
    "                plt.scatter(brisque_scores_1d, brisque_scores_1d, c=y_pred, cmap=\"viridis\")\n",
    "                plt.xlabel(\"Feature 1\")\n",
    "                plt.ylabel(\"Feature 2\")\n",
    "            scores_arr = [score for sub_arr in array.tolist() for score in sub_arr]\n",
    "            for score, label in zip(scores_arr, labels):\n",
    "                label_string = \"\"\n",
    "                if label == 1: \n",
    "                    label_string = \"True\"\n",
    "                else:\n",
    "                    label_string = \"False\"\n",
    "                scores_labels[score] = label_string\n",
    "        return scores_labels\n",
    "            \n",
    "        \n",
    "    def results(self):\n",
    "        blur_dict = dict(sorted(self.blur_effect().items(), key=lambda item: item[1]))\n",
    "        blur_arr = array(list(blur_dict.values())).reshape(-1, 1)\n",
    "        blur_label_dict = self.labeling(blur_arr, \"blur_label_model\")\n",
    "        \n",
    "        sharp_dict = dict(sorted(self.sharpen().items(), key=lambda item: item[1]))\n",
    "        sharp_arr = array(list(sharp_dict.values())).reshape(-1, 1)\n",
    "        sharp_label_dict = self.labeling(sharp_arr, \"sharp_label_model\")\n",
    "        \n",
    "        cb_dict = dict(sorted(self.contrast_brightness_effect().items(), key=lambda item: item[1]))\n",
    "        cb_arr = array(list(cb_dict.values())).reshape(-1, 1)\n",
    "        cb_label_dict = self.labeling(cb_arr, \"cb_label_model\")\n",
    "        \n",
    "        json.dump(blur_label_dict, open(\"blur_label_dict.json\", 'w'))\n",
    "        json.dump(sharp_label_dict, open(\"sharp_label_dict.json\", 'w'))\n",
    "        json.dump(cb_label_dict, open(\"cb_label_dict.json\", 'w'))\n",
    "        \n",
    "        return (blur_label_dict, sharp_label_dict, cb_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b3cc2da-b837-4cac-91a7-d7a1a5a9fa09",
   "metadata": {
    "id": "2b3cc2da-b837-4cac-91a7-d7a1a5a9fa09"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test = ImageAugLabeling(open_orig_2, 50, \"open_mouth_two\") \n",
    "# results = test.results()\n",
    "\n",
    "# blur_label_dict, sharp_label_dict, cb_label_dict = results\n",
    "'''\n",
    "This function and piece of code are only used if and only if the process of the labeling crashes \n",
    "your VM/driver after running it. Otherwise, you can run the code block as is with code below being commented\n",
    "out.\n",
    "'''\n",
    "\n",
    "def convert_key(in_dict):\n",
    "    return {float(k):v for k,v in in_dict.items()}\n",
    "\n",
    "blur_label_dict = convert_key(json.load(open(\"blur_label_dict.json\")))\n",
    "sharp_label_dict = convert_key(json.load(open(\"sharp_label_dict.json\")))\n",
    "cb_label_dict = convert_key(json.load(open(\"cb_label_dict.json\")))\n",
    "\n",
    "results = (blur_label_dict, sharp_label_dict, cb_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e20520cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "'''\n",
    "This piece of code is an additional padding via oversampling to deal with class imbalances that \n",
    "the initial augmentation was presenting.\n",
    "'''\n",
    "\n",
    "def find_first_false(input_dict):\n",
    "    for k, v in input_dict.items():\n",
    "        if v == 'False':\n",
    "            return k\n",
    "\n",
    "\n",
    "def padding_augmentation(aug_dict, padding=1000):\n",
    "    aug_thresh = find_first_false(aug_dict)\n",
    "    aug_count = Counter(aug_dict.values())\n",
    "    aug_pad_val = aug_count['False'] - aug_count['True']\n",
    "    random.seed(42)\n",
    "    aug_pad = [np.random.uniform(0, aug_thresh) for _ in range(0, int(aug_pad_val))]\n",
    "    aug_pad_dict = {score:'True' for score in aug_pad}\n",
    "    aug_pad_dict = dict(list(aug_pad_dict.items()) + list(aug_dict.items()))\n",
    "\n",
    "    aug_pad_true = [np.random.uniform(0, aug_thresh) for _ in range(0, padding)]\n",
    "    aug_pad_false = [np.random.uniform(aug_thresh, 100) for _ in range(0, padding)]\n",
    "    aug_pad_true_dict = {score:'True' for score in aug_pad_true}\n",
    "    aug_pad_false_dict = {score:'False' for score in aug_pad_false}\n",
    "    \n",
    "    \n",
    "    final_aug_dict = dict(list(aug_pad_true_dict.items()) + list(aug_pad_dict.items()) + list(aug_pad_false_dict.items()))\n",
    "    return final_aug_dict\n",
    "\n",
    "\n",
    "blur_label_dict_padded = padding_augmentation(blur_label_dict, 8000)\n",
    "sharp_label_dict_padded = padding_augmentation(sharp_label_dict, 8000)\n",
    "cb_label_dict_padded = padding_augmentation(cb_label_dict, 8000)\n",
    "\n",
    "results = (blur_label_dict_padded, sharp_label_dict_padded, cb_label_dict_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5937a55c-e773-4cca-9500-fa9c0a4baea5",
   "metadata": {
    "id": "5937a55c-e773-4cca-9500-fa9c0a4baea5"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class SwitchClassifier(BaseEstimator):\n",
    "    def __init__(self, classifier=LogisticRegression()):\n",
    "        self.classifier = classifier\n",
    "    \n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.classifier.fit(X, y)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        self.classifier.predict(X)\n",
    "        \n",
    "    def predict_proba(self, X, y=None):\n",
    "        return self.classifier.predict_proba(X)\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        return self.classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6dde6e63-ab9b-4549-8d1e-7e5586438c37",
   "metadata": {
    "id": "6dde6e63-ab9b-4549-8d1e-7e5586438c37"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns \n",
    "import ast\n",
    "\n",
    "class TrainAndTest():\n",
    "    def __init__(self, orig_img_fn, orig_img, results, test_size=0.2, verbose=None, display_train_test_results=None, plot_cm=None):\n",
    "        self.orig_img_fn = orig_img_fn\n",
    "        self.orig_img = orig_img\n",
    "        self.results = results\n",
    "        self.test_size = test_size\n",
    "        self.verbose = verbose or 0 \n",
    "        self.display_train_test_results = display_train_test_results or False\n",
    "        self.plot_cm = plot_cm or False\n",
    "        \n",
    "     \n",
    "    def grid_search_proc(self, x_train, y_train):\n",
    "    \n",
    "        pipe = Pipeline([('preprocessing', MinMaxScaler()), ('classifier', VotingClassifier(SwitchClassifier(),\n",
    "                                                                                           voting=\"soft\"))])\n",
    "\n",
    "        lr = LogisticRegression(random_state=42)\n",
    "        np.random.seed(42)\n",
    "        mnb = MultinomialNB()\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "        param_grid = [{'classifier': [lr], \n",
    "                       'preprocessing': [MinMaxScaler(feature_range=(0, 1))],\n",
    "                       \"classifier__C\": list(np.logspace(0, 4, 10))},\n",
    "                      {'classifier': [mnb], 'preprocessing':[MinMaxScaler(feature_range=(0, 1))],\n",
    "                       'classifier__alpha': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "                      {'classifier': [rf], \n",
    "                       'preprocessing': [MinMaxScaler(feature_range=(0, 1))],\n",
    "                       'classifier__n_estimators': [5, 10, 50, 100, 300],\n",
    "                       'classifier__min_samples_split': [3, 5, 10, 20],\n",
    "                       'classifier__max_depth': [3, 5, 10, 20]}]\n",
    "\n",
    "\n",
    "        clf = GridSearchCV(pipe, param_grid, cv = 5, n_jobs= -1, verbose=self.verbose)\n",
    "        clf.fit(x_train, y_train)\n",
    "        return clf    \n",
    "        \n",
    "    def aug_test_results(self, aug_dict, aug_name, model_fn):\n",
    "        aug_x, aug_y = array(list(aug_dict.keys())).reshape(-1, 1), np.array(list(aug_dict.values()))\n",
    "        aug_x_train, aug_x_test, aug_y_train, aug_y_test = train_test_split(aug_x, aug_y,\n",
    "                                                        test_size=self.test_size, random_state=42)\n",
    "        \n",
    "        grid_search = self.grid_search_proc(aug_x_train, aug_y_train)\n",
    "        grid_search_best = grid_search.best_estimator_\n",
    "        grid_search_best_str = str(grid_search_best)\n",
    "        grid_search_best_name = grid_search_best_str[0:grid_search_best_str.index('(')]\n",
    "\n",
    "        grid_search_cv_score = grid_search.best_score_*100\n",
    "        grid_search_test_score = grid_search.score(aug_x_test, aug_y_test)*100\n",
    "        \n",
    "        if self.display_train_test_results:\n",
    "            print(\"Best parameters:\")\n",
    "            print(grid_search_best)\n",
    "            print(\"Cross Validation Score: {:.2f}%\".format(grid_search_cv_score))\n",
    "            print(\"Test Dataset Score: {:.2f}%\".format(grid_search_test_score))\n",
    "\n",
    "        model_fn += \".joblib\"\n",
    "        joblib.dump(grid_search_best, model_fn)\n",
    "        aug_clf_model = joblib.load(model_fn)\n",
    "\n",
    "        if self.plot_cm:\n",
    "            aug_clf_model.fit(aug_x_train, aug_y_train)\n",
    "            aug_y_pred = aug_clf_model.predict(aug_x_test)\n",
    "            labels = ['True', 'False']\n",
    "            matrix = confusion_matrix(aug_y_test, aug_y_pred, labels = labels)\n",
    "            sns.heatmap(matrix, annot=True, xticklabels = labels, yticklabels = labels)\n",
    "            plt.ylabel('Actual Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.title('Confusion Matrix from Augmentation {} and {} Model'.format(aug_name, grid_search_best_name)) \n",
    "            plt.show()\n",
    "            plt.savefig('{}_{}.png'.format(aug_name, grid_search_best_name))\n",
    "            \n",
    "            \n",
    "            train_sizes, train_scores, test_scores = learning_curve(estimator=grid_search_best, \n",
    "                                                                    X=aug_x_train, y=aug_y_train,\n",
    "                                                       cv=10, train_sizes=np.linspace(0.1, 1.0, 10), n_jobs=1)\n",
    "            train_mean = np.mean(train_scores, axis=1)\n",
    "            train_std = np.std(train_scores, axis=1)\n",
    "            test_mean = np.mean(test_scores, axis=1)\n",
    "            test_std = np.std(test_scores, axis=1)\n",
    "            #\n",
    "            # Plot the learning curve\n",
    "            #\n",
    "            plt.plot(train_sizes, train_mean, color='blue', marker='o', markersize=5, label='Training Accuracy')\n",
    "            plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color='blue')\n",
    "            plt.plot(train_sizes, test_mean, color='green', marker='+', markersize=5, linestyle='--', label='Validation Accuracy')\n",
    "            plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color='green')\n",
    "            plt.title('{}: Learning Curve'.format(aug_name))\n",
    "            plt.xlabel('Training Data Size')\n",
    "            plt.ylabel('Model accuracy')\n",
    "            plt.grid()\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.show()\n",
    "            plt.savefig('{}_{}_Learning Curve'.format(aug_name, grid_search_best_name))\n",
    "            \n",
    "            ## Classification Report\n",
    "            print(\"{}: Classification Report\".format(aug_name))\n",
    "            print(classification_report(aug_y_test, aug_y_pred))\n",
    "        return aug_x_train, aug_y_train\n",
    "    \n",
    "    def test_display(self): \n",
    "        blur_label_dict, sharp_label_dict, cb_label_dict = self.results \n",
    "        blur_x_train, blur_y_train = self.aug_test_results(blur_label_dict, \"Blur Effect\", \"blur_clf\")\n",
    "        sharp_x_train, sharp_y_train = self.aug_test_results(sharp_label_dict, \"Sharpness Effect\", \"sharp_clf\")\n",
    "        cb_x_train, cb_y_train = self.aug_test_results(cb_label_dict, \"Contrast-Brightness Effect\", \"cb_clf\")\n",
    "        return blur_x_train, blur_y_train, sharp_x_train, sharp_y_train, cb_x_train, cb_y_train\n",
    "    \n",
    "    def final_testing(self):\n",
    "        obj = BRISQUE(self.orig_img_fn, url=False)\n",
    "        brisque_score = obj.score()\n",
    "        blur_x_train, blur_y_train, sharp_x_train, sharp_y_train, cb_x_train, cb_y_train = self.test_display()\n",
    "        \n",
    "        orig_img_fn = self.orig_img_fn[self.orig_img_fn.find(\"/\")+1:]\n",
    "        blur_clf = joblib.load(\"blur_clf.joblib\")\n",
    "        sharp_clf = joblib.load(\"sharp_clf.joblib\")\n",
    "        cb_clf = joblib.load(\"cb_clf.joblib\")\n",
    "\n",
    "        result = {}\n",
    "        aug_classifiers_dict = {\"Bluriness\": blur_clf, \"Sharpness\": sharp_clf, \"Contrast/Brightness\": cb_clf} \n",
    "        for aug_name, classifier_model in aug_classifiers_dict.items():\n",
    "            predicted_value = ast.literal_eval(classifier_model.predict([[brisque_score]])[0])\n",
    "            result[\"Acceptable {}\".format(aug_name)] = predicted_value\n",
    "        response = \"Response for Photo: {}\\n {}\".format(orig_img_fn, result) \n",
    "        print(response)\n",
    "        #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "666293e6-d035-4911-a9a2-ac535e6415fb",
   "metadata": {
    "id": "666293e6-d035-4911-a9a2-ac535e6415fb",
    "outputId": "982e8e5a-b764-41c2-ffbb-6aa80070e6ed"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "the input array must have size 3 along `channel_axis`, got (946, 580, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36mTrainAndTest.final_testing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinal_testing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    121\u001b[0m     obj \u001b[38;5;241m=\u001b[39m BRISQUE(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_img_fn, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 122\u001b[0m     brisque_score \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     blur_x_train, blur_y_train, sharp_x_train, sharp_y_train, cb_x_train, cb_y_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_display()\n\u001b[1;32m    125\u001b[0m     orig_img_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_img_fn[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morig_img_fn\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/brisque/brisque.py:33\u001b[0m, in \u001b[0;36mBRISQUE.score\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     32\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_image()\n\u001b[0;32m---> 33\u001b[0m     gray_image \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrgb2gray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     mscn_coefficients \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_mscn_coefficients(gray_image, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     35\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_pair_product_coefficients(mscn_coefficients)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/skimage/_shared/utils.py:394\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/skimage/color/colorconv.py:875\u001b[0m, in \u001b[0;36mrgb2gray\u001b[0;34m(rgb, channel_axis)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;129m@channel_as_last_axis\u001b[39m(multichannel_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrgb2gray\u001b[39m(rgb, \u001b[38;5;241m*\u001b[39m, channel_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute luminance of an RGB image.\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \n\u001b[1;32m    838\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;124;03m    >>> img_gray = rgb2gray(img)\u001b[39;00m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m     rgb \u001b[38;5;241m=\u001b[39m \u001b[43m_prepare_colorarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m     coeffs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.2125\u001b[39m, \u001b[38;5;241m0.7154\u001b[39m, \u001b[38;5;241m0.0721\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mrgb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m rgb \u001b[38;5;241m@\u001b[39m coeffs\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/skimage/color/colorconv.py:140\u001b[0m, in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr, force_copy, channel_axis)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape[channel_axis] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    138\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe input array must have size 3 along `channel_axis`, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m            \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    142\u001b[0m float_dtype \u001b[38;5;241m=\u001b[39m _supported_float_type(arr\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m float_dtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n",
      "\u001b[0;31mValueError\u001b[0m: the input array must have size 3 along `channel_axis`, got (946, 580, 4)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_result = TrainAndTest(closed_fn, closed_orig, results, 0.3, 2, True, True)\n",
    "final_result.final_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cefbaacf-f56f-4085-b575-9409d2b35cba",
   "metadata": {
    "id": "cefbaacf-f56f-4085-b575-9409d2b35cba",
    "outputId": "1a4c7363-d8a0-40a7-f6e0-8db6945b34a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for Photo: closed_mouth.png\n",
      " {'Acceptable Bluriness': True, 'Acceptable Sharpness': False, 'Acceptable Contrast/Brightness': True}\n",
      "CPU times: user 3.57 s, sys: 187 ms, total: 3.76 s\n",
      "Wall time: 22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_result_2 = TrainAndTest(closed_fn, closed_orig, results, 0.3)\n",
    "final_result_2.final_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83e466cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19.3\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "print(skimage.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5a816dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a62ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BRISQUE.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
